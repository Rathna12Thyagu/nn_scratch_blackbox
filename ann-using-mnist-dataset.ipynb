{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285}],"dockerImageVersionId":30213,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. GOAL\n\n#### Our goal is to build and train a neural network, which recognizes handwritten digits with a mind-blowing accuracy. It will be able to recognize the digits from 0 to 9.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# 2. REQUIRED LIBRARIES","metadata":{}},{"cell_type":"code","source":"import cv2   # it will allow us to load our images into the script\nimport numpy as np   # used for reformatting our own images\nimport tensorflow as tf   # main library used to load data sets, build neural networks, train them, etc.\nimport matplotlib.pyplot as plt   # used for visualization","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:15.095977Z","iopub.execute_input":"2022-08-22T13:23:15.096501Z","iopub.status.idle":"2022-08-22T13:23:15.103494Z","shell.execute_reply.started":"2022-08-22T13:23:15.096461Z","shell.execute_reply":"2022-08-22T13:23:15.101774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. LOADING AND PREPARING DATA\n\n- MNIST dataset contains 60,000 training examples and 10,000 testing examples of handwritten digits that are already classified correctly. \n- These images have a resolution of 28x28 pixels.\n- We will use the *keras* module, in order to load the dataset.\n- In order to get the dataset, we access the *mnist* object from the *keras.datasets*.\n- Then we call the *load_function* dataset. This function automatically splits the data appropriately and returns a tuple with the training data and a tuple with the testing data.","metadata":{}},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:15.111607Z","iopub.execute_input":"2022-08-22T13:23:15.112512Z","iopub.status.idle":"2022-08-22T13:23:15.485273Z","shell.execute_reply.started":"2022-08-22T13:23:15.112461Z","shell.execute_reply":"2022-08-22T13:23:15.483348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The shape of the training inputs:', X_train.shape)\nprint('The shape of the training labels:',y_train.shape)\nprint('The shape of the testing inputs:',X_test.shape)\nprint('The shape of the testing labels:',y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:15.487447Z","iopub.execute_input":"2022-08-22T13:23:15.487846Z","iopub.status.idle":"2022-08-22T13:23:15.49428Z","shell.execute_reply.started":"2022-08-22T13:23:15.487812Z","shell.execute_reply":"2022-08-22T13:23:15.493326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. PLOTTING THE DATA","metadata":{}},{"cell_type":"code","source":"# plotting the first 9 images in the train set of MNIST\n \nfig, axs = plt.subplots(3, 3)\ncnt = 0\nfor i in range(3):\n     for j in range(3):\n         axs[i, j].imshow(X_train[cnt])\n         cnt += 1","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:15.495593Z","iopub.execute_input":"2022-08-22T13:23:15.496965Z","iopub.status.idle":"2022-08-22T13:23:16.290094Z","shell.execute_reply.started":"2022-08-22T13:23:15.496909Z","shell.execute_reply":"2022-08-22T13:23:16.288776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. NORMALIZE THE DATA\n\n- In order to make the whole data easier to process, we are going to normalize it. This means that we scale down all the values so that they end up between 0 and 1.\n- For this we use the normalize function of *keras.uitils*.","metadata":{}},{"cell_type":"code","source":"X_train = tf.keras.utils.normalize(X_train, axis=1)\nX_test = tf.keras.utils.normalize(X_test, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:16.293641Z","iopub.execute_input":"2022-08-22T13:23:16.294468Z","iopub.status.idle":"2022-08-22T13:23:16.929624Z","shell.execute_reply.started":"2022-08-22T13:23:16.294415Z","shell.execute_reply":"2022-08-22T13:23:16.928282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. BUILDING THE NEURAL NETWORK\n\n- We use the *models* module from *keras* to create a new neural network. The *Sequential* constructor does this for us.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:16.931514Z","iopub.execute_input":"2022-08-22T13:23:16.932017Z","iopub.status.idle":"2022-08-22T13:23:16.941803Z","shell.execute_reply.started":"2022-08-22T13:23:16.931973Z","shell.execute_reply":"2022-08-22T13:23:16.940429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Now we have a model, which doesn't have any layers in it. Those have to be added manually.","metadata":{}},{"cell_type":"code","source":"model.add(tf.keras.layers.Flatten(input_shape=(28,28)))   # input layer","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:16.943637Z","iopub.execute_input":"2022-08-22T13:23:16.944145Z","iopub.status.idle":"2022-08-22T13:23:16.961376Z","shell.execute_reply.started":"2022-08-22T13:23:16.944099Z","shell.execute_reply":"2022-08-22T13:23:16.960379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We start out by adding a so-called *Flatten* layer as our first layer.\n- In order to add a layer to our model, we use the *add* function. Then we can choose the kind of layer that we want from the *layers* module.\n- We specified an input shape of 28x28 which represents the resolution of images.\n- What a flattened layer basically does is it flattens the input and makes it one dimensional. So instead of a 28x28 grid, we end up with 784 neurons lined up.","metadata":{}},{"cell_type":"code","source":"model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))   # 1st hidden layer\nmodel.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))   # 2nd hidden layer","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:16.964321Z","iopub.execute_input":"2022-08-22T13:23:16.965436Z","iopub.status.idle":"2022-08-22T13:23:16.996289Z","shell.execute_reply.started":"2022-08-22T13:23:16.965384Z","shell.execute_reply":"2022-08-22T13:23:16.995321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We added two dense layers. These are our hidden layers and increase the complexity of our model.\n- Both layers have 128 neurons each.\n- The activation function is ReLU function.\n- Dense layers connect every neuron of this layer with all the neurons of the next and previous layer.","metadata":{}},{"cell_type":"code","source":"model.add(tf.keras.layers.Dense(units=10, activation=tf.nn.softmax))   # output layer","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:16.998279Z","iopub.execute_input":"2022-08-22T13:23:16.999173Z","iopub.status.idle":"2022-08-22T13:23:17.018791Z","shell.execute_reply.started":"2022-08-22T13:23:16.999125Z","shell.execute_reply":"2022-08-22T13:23:17.017776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Last but not least we add an output layer. This one is also a dense layer but it only has 10 neurons and a different activation function.\n- The values of the 10 neurons indicate how much our model believes that the respective number is the right classification.\n- The first neuron is for the zero, the second for the one and so on.\n- The activation function that we use here is the *softmax* function. This function scales the output values so that they all add upto one. Thus it transforms the absolute values into relative values.- ","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:17.020079Z","iopub.execute_input":"2022-08-22T13:23:17.020574Z","iopub.status.idle":"2022-08-22T13:23:17.028118Z","shell.execute_reply.started":"2022-08-22T13:23:17.020526Z","shell.execute_reply":"2022-08-22T13:23:17.027173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. COMPILING THE MODEL\n\n- Before we start training and testing our model, we need to compile it first. This optimizes it and we can also choose a loss function.\n- An optimizer is a function or an algorithm that modifies the attributes of the neural network, such as weights and learning rate. Thus, it helps in reducing the overall loss and improve the accuracy. ","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:17.031177Z","iopub.execute_input":"2022-08-22T13:23:17.031868Z","iopub.status.idle":"2022-08-22T13:23:17.045459Z","shell.execute_reply.started":"2022-08-22T13:23:17.031829Z","shell.execute_reply":"2022-08-22T13:23:17.044082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. TRAINING AND TESTING\n\n- Now, we get to the essential part of the whole project - the training and testing.\n- For this, we just have to use the *fit* function of our model.","metadata":{}},{"cell_type":"code","source":"model.fit(X_train, y_train, epochs=10, batch_size=100)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:17.047452Z","iopub.execute_input":"2022-08-22T13:23:17.049445Z","iopub.status.idle":"2022-08-22T13:23:42.665814Z","shell.execute_reply.started":"2022-08-22T13:23:17.049391Z","shell.execute_reply":"2022-08-22T13:23:42.664549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- *epochs* - This number defines how many times our model is going to see the same data over and over again.\n- *batch_size* - This refers to the number of training examples utilized in one iteration.","metadata":{}},{"cell_type":"markdown","source":"# 9. MODEL EVALUATION\n\n- We use the evaluate method and pass our testing data, to determine the accuracy and the loss.","metadata":{}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, y_test)\nprint(loss)\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:42.667524Z","iopub.execute_input":"2022-08-22T13:23:42.667896Z","iopub.status.idle":"2022-08-22T13:23:43.568983Z","shell.execute_reply.started":"2022-08-22T13:23:42.667862Z","shell.execute_reply":"2022-08-22T13:23:43.568018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10. PREDICTION\n\n- We use *predict* method to make prediction of our image.","metadata":{}},{"cell_type":"code","source":"prediction = model.predict([X_test])\nprediction","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:43.570675Z","iopub.execute_input":"2022-08-22T13:23:43.571041Z","iopub.status.idle":"2022-08-22T13:23:44.266954Z","shell.execute_reply.started":"2022-08-22T13:23:43.571006Z","shell.execute_reply":"2022-08-22T13:23:44.265758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- This prediction consists of the ten activations or probabilities from the output neurons. \n- Since we need to generate a result out of that, we are going to use the *argmax* function. This function returns the index of the highest value.\n- In this case this is equivalent to the digit with the highest probability or activation.","metadata":{}},{"cell_type":"code","source":"# let us do prediction for single image\n\nprint('Probabilities: ', prediction[10])\nprint('\\n')\nprint('Prediction: ', np.argmax(prediction[10]))","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:44.268638Z","iopub.execute_input":"2022-08-22T13:23:44.268998Z","iopub.status.idle":"2022-08-22T13:23:44.275845Z","shell.execute_reply.started":"2022-08-22T13:23:44.268965Z","shell.execute_reply":"2022-08-22T13:23:44.27465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize the image\n\nplt.imshow(X_test[10])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:23:44.277793Z","iopub.execute_input":"2022-08-22T13:23:44.278149Z","iopub.status.idle":"2022-08-22T13:23:44.417208Z","shell.execute_reply.started":"2022-08-22T13:23:44.278116Z","shell.execute_reply":"2022-08-22T13:23:44.416104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that our model is pretty accurate. But it can still make mistakes, especially if we tend to write digits in a very unusual way.","metadata":{}},{"cell_type":"markdown","source":"**Reference:**\n\nhttps://www.amazon.in/Python-Bible-Networks-Tensorflow-Learning-ebook/dp/B0854PPMLS/ref=sr_1_1?crid=33REOU4OQVMGO&keywords=the+python+bible+volume+6&qid=1661174448&sprefix=the+python+bible+volume+6%2Caps%2C397&sr=8-1","metadata":{}}]}